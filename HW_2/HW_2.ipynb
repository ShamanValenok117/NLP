{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-24T07:57:05.316142Z",
     "start_time": "2021-11-24T07:57:04.305141Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-23T13:22:05.484627Z",
     "start_time": "2021-11-23T13:22:05.474627Z"
    }
   },
   "source": [
    "### Анализ датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-24T07:57:06.726144Z",
     "start_time": "2021-11-24T07:57:06.656144Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The CDC currently reports 99031 deaths. In gen...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>States reported 1121 deaths a small rise from ...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Politically Correct Woman (Almost) Uses Pandem...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                tweet label\n",
       "id                                                         \n",
       "1   The CDC currently reports 99031 deaths. In gen...  real\n",
       "2   States reported 1121 deaths a small rise from ...  real\n",
       "3   Politically Correct Woman (Almost) Uses Pandem...  fake"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./Materials/Constraint_Train.csv',index_col=0)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### создаем embedding для каждого слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-24T07:57:17.140160Z",
     "start_time": "2021-11-24T07:57:17.120160Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm import tqdm\n",
    "\n",
    "from gensim.models.word2vec import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-24T07:57:11.697151Z",
     "start_time": "2021-11-24T07:57:11.677151Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "\n",
    "eng_stopwords = stopwords.words('english') + [i for i in punctuation] + ['�','``','’']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-24T07:57:28.521176Z",
     "start_time": "2021-11-24T07:57:25.031171Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 6420/6420 [00:03<00:00, 1850.14it/s]\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "\n",
    "for i in tqdm(df.tweet): \n",
    "    result.append( [j for j in word_tokenize(i.lower()) if j not in eng_stopwords ])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-24T08:00:01.953620Z",
     "start_time": "2021-11-24T07:59:52.261428Z"
    }
   },
   "outputs": [],
   "source": [
    "# Word2Vec\n",
    "word_to_vec_tweets = Word2Vec(result, workers=4, vector_size=300, min_count=3, window=5, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-24T08:03:29.027911Z",
     "start_time": "2021-11-24T08:03:29.007911Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.5921233  -1.1200765  -1.2448933   0.411763    0.22529747  0.15750995\n",
      "  0.37977812  0.22201622  0.00494879  0.76706856  0.53205895  0.06524077\n",
      "  0.25412646 -0.05537247  1.1098365  -0.22657147  0.18047434 -0.8440129\n",
      "  2.6835637  -0.6430049   2.5529017   0.7119238  -0.6905735   1.9169923\n",
      " -0.05899691  0.5002548  -1.7540656   0.8503961   0.50157744  0.06769494]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('lions', 0.7208154201507568),\n",
       " ('putin', 0.7146435379981995),\n",
       " ('vladimir', 0.691994845867157),\n",
       " ('biotech', 0.661442756652832),\n",
       " ('bharat', 0.6567081809043884),\n",
       " ('covaxin', 0.590172290802002),\n",
       " ('donated', 0.585052490234375),\n",
       " ('developed', 0.5800663828849792),\n",
       " ('steal', 0.5773712992668152),\n",
       " ('company', 0.5667145252227783)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print( word_to_vec_tweets.wv['virus'][:30] )\n",
    "word_to_vec_tweets.wv.most_similar('russia')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "совпадает отлично эмбединг закончили."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-24T14:09:21.639524Z",
     "start_time": "2021-11-24T14:09:21.629524Z"
    }
   },
   "outputs": [],
   "source": [
    "y = np.array( (df.label == 'real').astype(np.int32).to_list() )\n",
    "\n",
    "result = np.array(result,dtype=object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### делаем функцию для случайного дропаута слов из предложения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-24T14:13:32.244876Z",
     "start_time": "2021-11-24T14:13:32.224876Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_word_dropout(text, probability = .5, fill_value = '#DROP#'):\n",
    "    '''\n",
    "        RANDOMLY DROP WORDS FROM GIVEN SENTENCE \n",
    "        WITH PROBABILITY \"probability\"\n",
    "    '''\n",
    "    \n",
    "    mask = np.random.choice(2,size = len(text), p=[1-probability,probability]).reshape(1,-1)\n",
    "\n",
    "    X = np.choose(mask,[text,np.full(shape = (1,len( text )) ,fill_value = fill_value)])[0]\n",
    "    return X\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-24T16:01:35.567005Z",
     "start_time": "2021-11-24T16:01:35.557005Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "take simple daily precautions help prevent spread respiratory illnesses like covid19 learn protect coronavirus covid-19 https //t.co/uargztrh5l https //t.co/biztxtukyk\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['#DROP#', 'simple', 'daily', '#DROP#', '#DROP#', '#DROP#',\n",
       "       'spread', 'respiratory', '#DROP#', '#DROP#', 'covid19', 'learn',\n",
       "       'protect', '#DROP#', 'covid-19', 'https', '//t.co/uargztrh5l',\n",
       "       'https', '//t.co/biztxtukyk'], dtype='<U17')"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print( ' '.join(result[10]) )\n",
    "make_word_dropout(text=result[10], probability = .5, fill_value = '#DROP#' )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### собираем итератор (+more efficient batching  = батчи будут отсортированы по размеру)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-24T16:02:13.422058Z",
     "start_time": "2021-11-24T16:02:13.412058Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_index(length, batch_size=15):\n",
    "    '''\n",
    "        RETURN LIST OF DATAFRAME (source) INDEXES WHERE TWEET LENGTH >= \"length\" \n",
    "    '''\n",
    "    # dict tweet_index:tweet_len\n",
    "    a = dict(zip(range(len(source)),map(len,source) ))\n",
    "    #a = kwargs['dict_index_len']\n",
    "    \n",
    "    b = [] \n",
    "    while len(b) < batch_size:\n",
    "        for i,j in a.items():\n",
    "            if j == length:\n",
    "                b.append(i)\n",
    "                if len(b) == batch_size:\n",
    "                    return b\n",
    "        length +=1\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-24T16:11:39.365854Z",
     "start_time": "2021-11-24T16:11:39.355854Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_index(source,length, batch_size=15):\n",
    "    '''\n",
    "        RETURN LIST OF DATAFRAME (source) INDEXES WHERE TWEET LENGTH >= \"length\" \n",
    "    '''\n",
    "    # dict tweet_index:tweet_len\n",
    "    a = dict(zip(range(len(source)),map(len,source) ))\n",
    "    \n",
    "    \n",
    "    b = [] \n",
    "    while len(b) < batch_size:\n",
    "        for i,j in a.items():\n",
    "            if j == length:\n",
    "                b.append(i)\n",
    "                if len(b) == batch_size:\n",
    "                    return b\n",
    "        length +=1\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-24T16:12:28.329923Z",
     "start_time": "2021-11-24T16:12:28.309923Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[141, 508, 571]"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_index(result,length=3,batch_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-24T16:12:59.502967Z",
     "start_time": "2021-11-24T16:12:59.482967Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_batch_indexes(source, BATCH_SIZE = 15, same_length = True):\n",
    "    '''\n",
    "        RETURN RANDOM LIST OF DATAFRAME INDEXES WITH SAME TWEET LENGTH (if same_length = True)\n",
    "             AND RANDOM CHOSEN #BATCH_SIZE# INDEXES\n",
    "        same_length: True  will return  a batch with the same tweet length //RANDOM CHOSEN TWEET LENGTH\n",
    "        same_length: False will return  a random choosen batch\n",
    "    '''\n",
    "    a = dict(zip(range(len(source)),map(len,source) ))\n",
    "    \n",
    "    if same_length:\n",
    "        length = np.random.choice( list(a.values()) )\n",
    "        batch_indexes = np.random.choice( get_index(source,length,batch_size = BATCH_SIZE*2 ) ,size = BATCH_SIZE )\n",
    "    else: \n",
    "        batch_indexes = np.random.choice( range(len(source)) ,size = BATCH_SIZE )\n",
    "        \n",
    "    return batch_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-24T16:13:23.818001Z",
     "start_time": "2021-11-24T16:13:23.798001Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([116,  58, 128])"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_batch_indexes(result,BATCH_SIZE=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Финальная итерирующая функция"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-25T13:33:34.979730Z",
     "start_time": "2021-11-25T13:33:34.967730Z"
    }
   },
   "outputs": [],
   "source": [
    "# Финальная итерирующая функция\n",
    "\n",
    "def iterate_minibatches(source,target, batch_size = 15, same_length=True, dropout=1, **kwargs):\n",
    "    # check for same_length\n",
    "    if same_length:\n",
    "        batch_indexes = get_batch_indexes(source,BATCH_SIZE = batch_size)\n",
    "    else:\n",
    "        batch_indexes = get_batch_indexes(source,BATCH_SIZE = batch_size, same_length = False)\n",
    "    \n",
    "    # make a minibatch \n",
    "    X = source[batch_indexes]\n",
    "    y = target[batch_indexes]\n",
    "    \n",
    "    # make dropout for the minibatch\n",
    "    if dropout !=1:\n",
    "        X = np.array( [make_word_dropout(text=i , probability = dropout, **kwargs ) for i in X], dtype=object)\n",
    "    \n",
    "    # make embeddings for each word in minibatch. \n",
    "    # word '#DROP#' will be embedded as np.full(300,1.)\n",
    "    # paddings '#PAD#' will be embedded as np.zeros(300)\n",
    "    # paddings requirement are calculated as max_len - len(X[i]) \n",
    "    new_X = []\n",
    "    max_len = max(map(len,X))\n",
    "    \n",
    "    for j in X:\n",
    "        while len(j) < max_len: j = np.append(j,['#PAD#'])\n",
    "        new_X.append(  \n",
    "            [word_to_vec_tweets.wv[i] if i in word_to_vec_tweets.wv else np.full(\n",
    "            (300,), 1.) if '#DROP#' in i else np.zeros(300) for i in j ])\n",
    "    X = np.array( new_X , dtype=float)\n",
    "    \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-25T14:26:20.997583Z",
     "start_time": "2021-11-25T14:26:20.977583Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_whole_source_embedding(X,use_tqdm=True):\n",
    "    new_X = []\n",
    "    max_len = max(map(len,X))\n",
    "    if use_tqdm:\n",
    "        for j in tqdm(X):\n",
    "            while len(j) < max_len: j = np.append(j,['#PAD#'])\n",
    "            new_X.append(  \n",
    "                [word_to_vec_tweets.wv[i] if i in word_to_vec_tweets.wv else np.full(\n",
    "                (300,), 1.) if '#DROP#' in i else np.zeros(300) for i in j ])\n",
    "        X = np.array( new_X , dtype=float)\n",
    "        \n",
    "    else:\n",
    "        for j in X:\n",
    "            while len(j) < max_len: j = np.append(j,['#PAD#'])\n",
    "            new_X.append(  \n",
    "                [word_to_vec_tweets.wv[i] if i in word_to_vec_tweets.wv else np.full(\n",
    "                (300,), 1.) if '#DROP#' in i else np.zeros(300) for i in j ])\n",
    "        X = np.array( new_X , dtype=float)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-24T14:42:29.019329Z",
     "start_time": "2021-11-24T14:42:28.999329Z"
    }
   },
   "source": [
    "#### Проверка итерирующей функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-24T16:13:37.189020Z",
     "start_time": "2021-11-24T16:13:37.169020Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([83, 38, 61])"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_batch_indexes(result,BATCH_SIZE = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-25T13:33:40.120739Z",
     "start_time": "2021-11-25T13:33:40.100739Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 0]), 3, [26, 26, 26])"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l,n = iterate_minibatches(result,y,batch_size = 3, same_length=False, dropout=1)\n",
    "n, len(l), list( map(len,l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### модель 2directional LSTM + Dense(Linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-24T13:07:08.200981Z",
     "start_time": "2021-11-24T13:07:06.650979Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-24T15:59:44.104848Z",
     "start_time": "2021-11-24T15:59:44.094848Z"
    }
   },
   "outputs": [],
   "source": [
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(result, y, test_size=0.33, random_state=255)\n",
    "X_train = np.array( X_train, dtype=object)\n",
    "X_test = np.array( X_test, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T07:16:59.568889Z",
     "start_time": "2021-11-26T07:16:59.538889Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (lstm): LSTM(300, 128, batch_first=True, bidirectional=True)\n",
      "  (dense): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# class 2dir_LSTM + DENSE\n",
    "class Net(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.lstm = torch.nn.LSTM(input_size=300, hidden_size=128,batch_first = True, bidirectional=True) #dropout=.3,num_layers=2\n",
    "        self.dense = torch.nn.Linear(in_features=128, out_features = 1, bias = True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        embeddings, (shortterm, longterm) = self.lstm(x)\n",
    "        longterm = torch.add(longterm[0],longterm[1])/2\n",
    "        predict = torch.sigmoid(self.dense(longterm))\n",
    "        return predict\n",
    "    \n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T07:17:23.614924Z",
     "start_time": "2021-11-26T07:17:10.809905Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train\n",
    "criteria = torch.nn.BCELoss()\n",
    "\n",
    "EPOCHS = 5\n",
    "batch_size = 15\n",
    "one_epoch_size = len(X_train)//batch_size\n",
    "min_loss = 1e-5\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for iteration in tqdm(range(one_epoch_size)):\n",
    "        l,n = iterate_minibatches(X_train,y_train,batch_size = batch_size, same_length=True, dropout=1)\n",
    "        #l = np.array(l, dtype=np.float64)\n",
    "        l = torch.from_numpy(l).float()\n",
    "\n",
    "        n = torch.from_numpy(n.reshape(-1,1)).float()\n",
    "        \n",
    "        v = net(l)\n",
    "\n",
    "        loss = criteria(v,n)\n",
    "        if loss < min_loss: break\n",
    "        print('loss = ',loss)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer = torch.optim.RMSprop( net.parameters(), lr = 0.01)\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    # at the end of each epoch print the last loss\n",
    "    print(f'epoch {epoch}. Loss = {loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T07:21:56.931598Z",
     "start_time": "2021-11-26T07:21:56.911598Z"
    }
   },
   "outputs": [],
   "source": [
    "# train function\n",
    "def net_train(model = net, EPOCHS = 5, batch_size = 15,min_loss = 1e-5, **kwargs ):\n",
    "    criteria = torch.nn.BCELoss()\n",
    "    one_epoch_size = len(X_train)//batch_size\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        for iteration in tqdm(range(one_epoch_size)):\n",
    "            l,n = iterate_minibatches(X_train,y_train, batch_size = batch_size, same_length=True,  **kwargs )\n",
    "            #l = np.array(l, dtype=np.float64)\n",
    "            l = torch.from_numpy(l).float()\n",
    "\n",
    "            n = torch.from_numpy(n.reshape(-1,1)).float()\n",
    "\n",
    "            v = model(l)\n",
    "\n",
    "            loss = criteria(v,n)\n",
    "            if loss < min_loss: break\n",
    "            #print('loss = ',loss)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer = torch.optim.RMSprop( net.parameters(), lr = 0.01 )\n",
    "\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        # at the end of each epoch print the last loss\n",
    "    print(f'epoch {epoch +1}. Loss = {loss}')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T07:17:47.948960Z",
     "start_time": "2021-11-26T07:17:41.076949Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███▏                                     | 22/286 [00:02<00:32,  8.08it/s]\n",
      "  2%|█                                         | 7/286 [00:00<00:38,  7.22it/s]\n",
      "  1%|▌                                         | 4/286 [00:00<00:43,  6.56it/s]\n",
      "  6%|██▍                                      | 17/286 [00:02<00:34,  7.69it/s]\n",
      "  1%|▍                                         | 3/286 [00:00<00:30,  9.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5. Loss = 8.110688213491812e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "net_train(model = net )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Проверка на тестовой выборке:\n",
    "Делаем проверочную функцию для X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T07:18:02.462982Z",
     "start_time": "2021-11-26T07:17:53.299967Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 22/22 [00:09<00:00,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test loss is 8.27254867553711\n",
      "accuracy =  0.7390278433223219\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.67      0.90      0.77      1012\n",
      "        real       0.87      0.59      0.70      1107\n",
      "\n",
      "    accuracy                           0.74      2119\n",
      "   macro avg       0.77      0.75      0.73      2119\n",
      "weighted avg       0.77      0.74      0.73      2119\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def net_evaluate(model = net):    \n",
    "    times = len(X_test) // 100 \n",
    "    new_v = torch.tensor([])\n",
    "\n",
    "    for  i in tqdm(range(times+1)):\n",
    "        try:\n",
    "            new_X = make_whole_source_embedding(X_test[i*100:i*100+100], use_tqdm=False)\n",
    "        except:\n",
    "            new_X = make_whole_source_embedding(X_test[i*100:], use_tqdm=False)\n",
    "\n",
    "        new_X =  torch.from_numpy(new_X).float()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            v = model(new_X)\n",
    "\n",
    "        new_v = torch.cat([new_v,v])\n",
    "\n",
    "    new_y = torch.from_numpy(y_test.reshape(-1,1)).float()        \n",
    "    loss = criteria(new_v,new_y)\n",
    "    print(f'The test loss is {loss}')\n",
    "\n",
    "    y_pred = (new_v > 0.5).numpy().astype(int).reshape(1,-1)[0]\n",
    "    \n",
    "    assert len(y_pred) == len(X_test)\n",
    "    accuracy = y_pred == y_test\n",
    "    \n",
    "    print('accuracy = ', np.sum(accuracy) / len(accuracy) )\n",
    "    \n",
    "    print(classification_report(y_test, y_pred,target_names=['fake','real']))\n",
    "    return None\n",
    "\n",
    "net_evaluate(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T10:16:41.661360Z",
     "start_time": "2021-11-26T10:16:41.651360Z"
    }
   },
   "outputs": [],
   "source": [
    "a = {'model':[],'f1_score':[] }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T10:16:50.932373Z",
     "start_time": "2021-11-26T10:16:50.912373Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': ['2directional LSTM + Dense(Linear)'], 'f1_score': ['0.74']}"
      ]
     },
     "execution_count": 686,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['model'].append('2directional LSTM + Dense(Linear)')\n",
    "a['f1_score'].append('0.74')\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Точность уже 0.74 неплохо. что можно сделать еще."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### модель 2directional LSTM + Dense(Linear) + WORD_Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T07:22:19.106630Z",
     "start_time": "2021-11-26T07:22:02.901606Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████▍                                    | 31/286 [00:05<00:41,  6.17it/s]\n",
      "  0%|                                                  | 0/286 [00:00<?, ?it/s]\n",
      " 24%|█████████▋                               | 68/286 [00:09<00:29,  7.28it/s]\n",
      "  3%|█▍                                       | 10/286 [00:01<00:42,  6.45it/s]\n",
      "  0%|▏                                         | 1/286 [00:00<00:59,  4.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5. Loss = 5.28496173046733e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "net_train(model = net,**{'dropout':.5} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T07:22:34.698652Z",
     "start_time": "2021-11-26T07:22:25.147639Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 22/22 [00:09<00:00,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test loss is 20.221128463745117\n",
      "accuracy =  0.6281264747522416\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.56      0.99      0.72      1012\n",
      "        real       0.98      0.30      0.45      1107\n",
      "\n",
      "    accuracy                           0.63      2119\n",
      "   macro avg       0.77      0.64      0.59      2119\n",
      "weighted avg       0.78      0.63      0.58      2119\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "net_evaluate(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T10:18:52.235543Z",
     "start_time": "2021-11-26T10:18:52.215543Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': ['2directional LSTM + Dense(Linear)',\n",
       "  '2directional LSTM + Dense(Linear) + WORD_Dropout'],\n",
       " 'f1_score': ['0.74', '0.63']}"
      ]
     },
     "execution_count": 687,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['model'].append('2directional LSTM + Dense(Linear) + WORD_Dropout')\n",
    "a['f1_score'].append('0.63')\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С дропаутом слов оказалось хуже. \n",
    "А если с дропаутом скрытых состояний?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### модель 2directional LSTM + Dense(Linear) + LSTM_hidden_state_Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T07:25:46.589922Z",
     "start_time": "2021-11-26T07:25:46.559922Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (lstm): LSTM(300, 128, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
      "  (dense): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.lstm = torch.nn.LSTM(input_size=300, hidden_size=128,batch_first = True, bidirectional=True,dropout=.5,num_layers=2) #dropout=.3,num_layers=2\n",
    "        self.dense = torch.nn.Linear(in_features=128, out_features = 1, bias = True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        embeddings, (shortterm, longterm) = self.lstm(x)\n",
    "        longterm = torch.add(longterm[0],longterm[1])/2\n",
    "        predict = torch.sigmoid(self.dense(longterm))\n",
    "        return predict\n",
    "    \n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T07:27:38.486082Z",
     "start_time": "2021-11-26T07:27:29.593068Z"
    }
   },
   "outputs": [],
   "source": [
    "net_train(model = net )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T07:27:54.469104Z",
     "start_time": "2021-11-26T07:27:38.876082Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 22/22 [00:15<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test loss is 8.553658485412598\n",
      "accuracy =  0.8692779613025012\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.84      0.89      0.87      1012\n",
      "        real       0.90      0.85      0.87      1107\n",
      "\n",
      "    accuracy                           0.87      2119\n",
      "   macro avg       0.87      0.87      0.87      2119\n",
      "weighted avg       0.87      0.87      0.87      2119\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "net_evaluate(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Точность выросла 0.87."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T10:18:52.235543Z",
     "start_time": "2021-11-26T10:18:52.215543Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': ['2directional LSTM + Dense(Linear)',\n",
       "  '2directional LSTM + Dense(Linear) + WORD_Dropout',\n",
       "  '2directional LSTM + Dense(Linear) + LSTM_hidden_state_Dropout'],\n",
       " 'f1_score': ['0.74', '0.63', '0.87']}"
      ]
     },
     "execution_count": 688,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['model'].append('2directional LSTM + Dense(Linear) + LSTM_hidden_state_Dropout')\n",
    "a['f1_score'].append('0.87')\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### модель LSTM + Dense(Linear)  without Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T10:10:56.021874Z",
     "start_time": "2021-11-26T10:10:56.001874Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (lstm): LSTM(300, 128, batch_first=True)\n",
      "  (dense): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.lstm = torch.nn.LSTM(input_size=300, hidden_size=128,batch_first = True, bidirectional=False) #dropout=.3,num_layers=2\n",
    "        self.dense = torch.nn.Linear(in_features=128, out_features = 1, bias = True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        embeddings, (shortterm, longterm) = self.lstm(x)\n",
    "        predict = torch.sigmoid(self.dense(longterm))\n",
    "        return predict.squeeze(0)\n",
    "    \n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T07:36:32.236833Z",
     "start_time": "2021-11-26T07:36:21.112817Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|██████████████████▏                     | 130/286 [00:07<00:08, 18.56it/s]\n",
      "  6%|██▌                                      | 18/286 [00:01<00:15, 17.82it/s]\n",
      "  5%|█▊                                       | 13/286 [00:00<00:19, 13.98it/s]\n",
      " 12%|████▊                                    | 34/286 [00:02<00:15, 16.26it/s]\n",
      "  0%|▏                                         | 1/286 [00:00<00:17, 16.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5. Loss = 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "net_train(model = net )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T11:41:31.356751Z",
     "start_time": "2021-11-26T11:41:25.583741Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 22/22 [00:05<00:00,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test loss is 0.6927607655525208\n",
      "accuracy =  0.5181689476168003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.33      0.01      0.02      1012\n",
      "        real       0.52      0.98      0.68      1107\n",
      "\n",
      "    accuracy                           0.52      2119\n",
      "   macro avg       0.43      0.50      0.35      2119\n",
      "weighted avg       0.43      0.52      0.36      2119\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "net_evaluate(model = net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Без 2 directional (только LSTM) - результат 0.65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T10:20:17.853664Z",
     "start_time": "2021-11-26T10:20:17.833664Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': ['2directional LSTM + Dense(Linear)',\n",
       "  '2directional LSTM + Dense(Linear) + WORD_Dropout',\n",
       "  '2directional LSTM + Dense(Linear) + LSTM_hidden_state_Dropout',\n",
       "  'LSTM + Dense(Linear)'],\n",
       " 'f1_score': ['0.74', '0.63', '0.87', '0.65']}"
      ]
     },
     "execution_count": 689,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['model'].append('LSTM + Dense(Linear)')\n",
    "a['f1_score'].append('0.65')\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### модель LSTM + Dense(Linear)  + LSTM_hidden_state_Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T09:01:01.916969Z",
     "start_time": "2021-11-26T09:01:01.886969Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (lstm): LSTM(300, 128, num_layers=2, batch_first=True)\n",
      "  (dense): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.lstm = torch.nn.LSTM(input_size=300, hidden_size=128,batch_first = True, bidirectional=False,dropout=.5,num_layers=2) \n",
    "        self.dense = torch.nn.Linear(in_features=128, out_features = 1, bias = True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        embeddings, (shortterm, longterm) = self.lstm(x)\n",
    "        longterm = (longterm[0]+longterm[1])/2\n",
    "        predict = torch.sigmoid(self.dense(longterm))\n",
    "        return predict\n",
    "    \n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T08:59:04.970802Z",
     "start_time": "2021-11-26T08:58:37.705762Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|██████████████████████▌                 | 161/286 [00:16<00:12,  9.65it/s]\n",
      "  8%|███▍                                     | 24/286 [00:03<00:34,  7.59it/s]\n",
      "  6%|██▍                                      | 17/286 [00:01<00:29,  9.09it/s]\n",
      " 13%|█████▎                                   | 37/286 [00:04<00:27,  8.96it/s]\n",
      "  4%|█▌                                       | 11/286 [00:01<00:34,  7.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5. Loss = 5.2770928959944285e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "net_train(model = net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T08:59:20.686826Z",
     "start_time": "2021-11-26T08:59:10.991810Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 22/22 [00:09<00:00,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test loss is 14.961292266845703\n",
      "accuracy =  0.6965549787635678\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.72      0.60      0.66      1012\n",
      "        real       0.68      0.78      0.73      1107\n",
      "\n",
      "    accuracy                           0.70      2119\n",
      "   macro avg       0.70      0.69      0.69      2119\n",
      "weighted avg       0.70      0.70      0.69      2119\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "net_evaluate(model = net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM + DENSE + Dropout результат 0.70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T10:20:17.853664Z",
     "start_time": "2021-11-26T10:20:17.833664Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': ['2directional LSTM + Dense(Linear)',\n",
       "  '2directional LSTM + Dense(Linear) + WORD_Dropout',\n",
       "  '2directional LSTM + Dense(Linear) + LSTM_hidden_state_Dropout',\n",
       "  'LSTM + Dense(Linear)',\n",
       "  'LSTM + Dense(Linear) + LSTM_hidden_state_Dropout'],\n",
       " 'f1_score': ['0.74', '0.63', '0.87', '0.65', '0.70']}"
      ]
     },
     "execution_count": 690,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['model'].append('LSTM + Dense(Linear) + LSTM_hidden_state_Dropout')\n",
    "a['f1_score'].append('0.70')\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM + Dense(Linear) + WORD_Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T10:10:36.689847Z",
     "start_time": "2021-11-26T10:09:59.497793Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|█████████████████▍                      | 125/286 [00:26<00:34,  4.73it/s]\n",
      "  3%|█▎                                        | 9/286 [00:01<00:44,  6.29it/s]\n",
      " 11%|████▌                                    | 32/286 [00:05<00:45,  5.63it/s]\n",
      "  7%|██▊                                      | 20/286 [00:03<00:46,  5.78it/s]\n",
      "  0%|▏                                         | 1/286 [00:00<00:51,  5.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5. Loss = 5.881017273168254e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "net_train(model = net,**{'dropout':0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T10:11:22.467911Z",
     "start_time": "2021-11-26T10:11:16.553903Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 22/22 [00:05<00:00,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test loss is 0.6927607655525208\n",
      "accuracy =  0.5181689476168003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.33      0.01      0.02      1012\n",
      "        real       0.52      0.98      0.68      1107\n",
      "\n",
      "    accuracy                           0.52      2119\n",
      "   macro avg       0.43      0.50      0.35      2119\n",
      "weighted avg       0.43      0.52      0.36      2119\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "net_evaluate(model = net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T10:21:01.597725Z",
     "start_time": "2021-11-26T10:21:01.577725Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': ['2directional LSTM + Dense(Linear)',\n",
       "  '2directional LSTM + Dense(Linear) + WORD_Dropout',\n",
       "  '2directional LSTM + Dense(Linear) + LSTM_hidden_state_Dropout',\n",
       "  'LSTM + Dense(Linear)',\n",
       "  'LSTM + Dense(Linear) + LSTM_hidden_state_Dropout',\n",
       "  'LSTM + Dense(Linear) + WORD_Dropout'],\n",
       " 'f1_score': ['0.74', '0.63', '0.87', '0.65', '0.70', '0.52']}"
      ]
     },
     "execution_count": 691,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['model'].append('LSTM + Dense(Linear) + WORD_Dropout')\n",
    "a['f1_score'].append('0.52')\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T10:24:45.193040Z",
     "start_time": "2021-11-26T10:24:45.163040Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2directional LSTM + Dense(Linear) + LSTM_hidde...</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2directional LSTM + Dense(Linear)</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LSTM + Dense(Linear) + LSTM_hidden_state_Dropout</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LSTM + Dense(Linear)</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2directional LSTM + Dense(Linear) + WORD_Dropout</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LSTM + Dense(Linear) + WORD_Dropout</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model f1_score\n",
       "2  2directional LSTM + Dense(Linear) + LSTM_hidde...     0.87\n",
       "0                  2directional LSTM + Dense(Linear)     0.74\n",
       "4   LSTM + Dense(Linear) + LSTM_hidden_state_Dropout     0.70\n",
       "3                               LSTM + Dense(Linear)     0.65\n",
       "1   2directional LSTM + Dense(Linear) + WORD_Dropout     0.63\n",
       "5                LSTM + Dense(Linear) + WORD_Dropout     0.52"
      ]
     },
     "execution_count": 697,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(a)\n",
    "results.sort_values(by='f1_score',ascending=False,inplace=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T10:26:34.985194Z",
     "start_time": "2021-11-26T10:26:34.965194Z"
    }
   },
   "source": [
    "Самый лучший результат показала модель: \n",
    "__\"2directional LSTM + Dense(Linear) + LSTM_hidden_state_Dropout\"__\n",
    "\n",
    "с резульатом __f1_score = 0.87__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
